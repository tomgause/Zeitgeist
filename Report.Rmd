---
title: "Zeitgeist Analysis"
author: "Tom Gause and Liam O'Brien"
date: "May 20, 2022"
header-includes:
- \usepackage{listings}
- \usepackage{amsmath, amsthm, amssymb, amsfonts}
- \usepackage{graphicx}
output: 
- pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction    
For the past four years at Middlebury College, a small team of students who write for the Middlebury Campus, the school's student newspaper, have designed a survey called the Zeitgeist. The intent of this survey is to get a basic idea of student behavior and attitude on campus. The survey is totally anonymous, and this lets the Zeitgeist team ask a range of sensitive questions such as "Have you ever broken the Honor Code?", "Have you been a victim of sexual assault?", and "Are you happy"? Each year, this survey, which takes 10-20 minutes to complete, is sent to the entire student body. When the responses are collected, the Middlebury Campus analyzes the data and releases an article summarizing some of the significant results of the survey (note that this article shares statistics only, the Zeitgeist team avoids any opinion writing). The Zeitgeist project is the largest and most comprehensive student census at Middlebury.   
In Spring 2022, the Zeitgeist team released the Zeitgeist 4.0. They collected 1134 responses of 2837 undergraduates--approximately 40% of the student population--and published a  \href{https://www.middleburycampus.com/article/2022/05/zeitgeist-4-0-2022}{summary article}. For our final project, we chose to answer the following question: are the Zietgeist 4.0 respondents representative of the Middlebury student population?   
Our null hypothesis is: The Zeitgeist is a random sample from the Middlebury student population. To evaluate this hypothesis, we used 5 metrics--Class (class year), Gender (gender identification), Race (ethnicity), Geographic Distribution (hometown), and Major (academic)--and collected data for each of these metrics from the Zeitgeist summary post referenced above. For our Middlebury College population data, we collected responses from various administrators and public datasets. See Methods, Data Collection for details.  

# Methods    
As we are testing our hypothesis with a large number of metrics, we pre-planned the following steps to avoid a type I error, i.e. avoid p-hacking. First, we decided to only run permutation tests. We used the formula $\alpha^* = 1-(1-\alpha)^{\frac{1}{k}}$ where $\alpha = 0.05$ and $k = 5$ to determine the value $<\alpha^* = \simeq 0.0102$ at which the p-value is considered statistically significant. Next, there is some variation in the features of the Zeitgeist and Middlebury Administration college data. To do analysis, we need to combine or remove some features from both dataset. To avoid bias, these data mutations were made before running our first phase of statistical tests. If the p-values from any of the Phase 1 metric tests came up significant, we would engage in a series of Phase 2 tests where we would alter the data assumptions made about the metrics before Phase 1 and re-test against the hypothesis. This process will help ensure any detected significance is not due to falsely made assumptions. 

For each of our five categories (gender, graduation year, race, region of residence, and major), we perform a permutation test. In each, we treat the Zeitgeist data like a sample from the administration data, which represents the Middlebury population. Our null hypothesis $H_0$ is that the Zeitgeist data is a random sample from the administration data. We use mean absolute error (MAE) as our test statistic for our Zeitgeist data.
\begin{equation*}
\text{MAE} = \frac{1}{n}\sum |\text{observed} - \text{expected}|.
\end{equation*}
We are summing over each categorical variable, and $n$ is the number of categorical variables. The observed count is the number of students in a category, and the expected count is the number of students that would be in the category if the proportion of students in the Zeitgeist sample was equal to the proportion in the population at Middlebury---as provided by the administration data. 

### Data Collection
The Zeitgeist data was collected from \href{https://www.middleburycampus.com/article/2022/05/zeitgeist-4-0-2022}{this article}. It is unknown what data modification/cleaning was done before publishing the article, so we treat this data as ground truth for Zeitgeist. As the Zeitgeist survey was done during the spring semester in 2022, we aimed to retrieve data from Middlebury during the spring of 2022 as well. The data from Middlebury’s administration was collected from  the \href{Undergraduate College | Middlebury}{\textit{Office of Assessment and Institutional Research}}. Their \textit{Spring 2022 Enrollment} document provided us information about the total enrollment at Middlebury by gender and by ethnicity. The Director of Assessment and Institutional Research at Middlebury, Adela Langrock, generously put together geographic data for us; it totals the states of residence for the enrolled students in the spring of 2022. We did not have the number of each graduating class enrolled in the spring of 2022; instead, we multiplied the proportion of each class in the fall of 2021 by the total enrollment for the spring of 2022. We are assuming that the proportions of each graduating class is the same in the fall and spring semesters. The enrollment by graduation year for the fall is contained in the \textit{Fall 2021 Student Profile} on the Office of Assessment and Institutional Research webpage linked above.

### Data Modification Pre Phase 1  
All of the questions in the Zeitgeist included an "I prefer not to answer" option. This option was provided for numerous reasons--some respondents may have felt that the options provided did not apply to them, others may have been concerned that an adversary on the Zeitgeist Team would discover their identity from the provided information and use their data in a malicious manner. For the metrics we chose to test, less than $1%$ of respondents selected the "I prefer not to answer" option. For this reason, we have omitted this category from the data for all metrics for the initial testing phase. When describing the options available to respondents, we will omit the “I prefer not to answer” option.

After removing the "I prefer not to answer" data, the Class Year, and Academic Major metrics matched one-to-one, so we deemed these data ready for analysis.  

##### Gender  
The Zeitgeist included six multiple-choice options for gender-identification: Cisgender Female, Cisgender Male, Non-Binary, Transgender Male, Transgender Female and These Options Don't Define Me. Administration only had two categories: Female, Male. We chose to consider only the following statistics: Cisgender Female (Zeitgeist)::Female (Admin) and Cisgender Male (Zeitgeist)::Male (Admin). This decision was made to uphold statistical rigor and avoid mis-gendering Zeitgeist respondents. We regret that folks who selected genders other than Cisgender Female and Cisgender Male were forced to select Female or Male in their College Applications.  

#####Race
For the Race section of the Zeitgeist, students were given eight options from which they were free to choose as many as they wished. These options were: “White”, “Asian’, “Hispanic or Latino Origin”, “Black or African American”, “Middle Eastern or North African”, “American Indian or Alaskan Native” and “Native Hawaiian or other Pacific Islander”. There were 1267 responses, of 1134 respondents, meaning at maximum, 153 respondents selected more than one race. From our data, we have no way to determine what selections these 153 respondents made, meaning the data has unexplainable variance. The Middlebury Admin data only allows a single selection. It does not include a category for “Middle Eastern or North African” and includes categories for “International”, “Race and/or ethnicity unknown”, and “Two or more races”. Rather than make assumptions about respondents’/students’ race, we only selected features from datasets that matched one-to-one. As we have no way to remove the variance from respondents who selected multiple races, we must inspect results from permutation testing on this data with extreme scrutiny.   

#####Geographic Location
We did not receive the number of international students enrolled during the spring of 2022; therefore, we are excluding international students from our statistical analysis.


###Phase 2 Testing
If we see any significant differences, we want to change our assumptions and run the test again to ensure that we are not making any false claims based on false assumptions. In this section, I will outline our changes in assumptions for phase 2. Note that this section was written prior to doing any statistical tests on our data.

Like before, our Class Year, Geographic Location, and Academic Major metrics matched one-to-one after removing the “I prefer not to answer” category, so we were not making any significant assumptions and will not run phase 2 testing for these categories.

#####Gender
We know that Zeitgeist surveyed respondents with six multiple-choice options for gender identification. Middlebury, however, only had two options two fill in: “Female” and “Male”. For our phase 1 testing, we just ignored the Zeitgeist responses that were neither “Female” nor “Male”. In phase 2 testing, we will make the assumption that people in other gender categories were forced to respond either “Female” or “Male”. We will assume that such a respondent’s choice of “Female” or “Male” was random with probability 0.5 of choosing either category. Our reasoning is that when non-binary people apply to Middlebury and have to select one of two categories which don't apply to them, they will pick randomly. After randomly re-assigning gender non-binary people, we will run our statistical test again.

#####Race
For phase 1 testing, we made some big assumptions about how we should test our data (see data modification above). For phase 2, we want to try a different approach. We will assume that those in administration’s data who selected “Two or more races” would have selected exactly two races if they were given the Zeitgeist survey. We will randomly assign each "Two or more races" selection in the administration data to two of the race categories with according to the distribution at Middlebury given by the admin data (excluding the two or more races category). Here we are adjusting our assumptions about the population rather than the Zeitgeist sample. After our changes we will run the test again with our new data.

#####Major
At Middlebury, students often don't declare their major until the end of their second year---even after they know what they want to study. In phase 2 we will assume that some students marked down their intended major in the Zeitgeist survey even though they were still "undeclared" according to Middlebury's records. To account for this, we will remove the "undeclared" category from both data sets---making the assumption that people who gave their intended major on the Zeitgeist survey, while being undeclared, are not distributed in any special way. That is, they follow the distributions of majors already present in both the Middlebury and Zeitgeist data.
  
``` {r phase1.data}
library(tidyverse)
library(dplyr)
Gender.Data.Phase1 <- Gender.Data.Raw %>%
  select(Cisgender Female, Cisgender Male)

```  


#Results

###Class
When looking at our class category, we observe a $p$-value of about 0.17437, meaning that we have about a 17% chance of observing something more extreme than the test statistic of our sample given that the proportion of students in each class is randomly sampled from the Middlebury population. See \textbf{Exhibit B} in the appendix for the `R` code. This is not rare enough to reject the null hypothesis because the $p$-value is larger than $\alpha^*$

###Geography
For our geography category, we get a $p$-value of about 0.04467 meaning there is about a 4% chance of observing something more rare than our sample's test statistic given that Zeitgeist is randomly sampled from the administration's population data (\textbf{Exhibit C}). This is still larger than $\alpha^*$, so we do not have enough evidence to reject the null hypothesis.

4) Conclusion: Explain how your research question was answered and what possible
meaningful takeaway you/the reader should have.

Thank Yous:

Consult for ethical data modification Sophie Hochman, Joint GSFS Sociology Major.


#Appendix
In the appendix is the `R` code we used for our data modifications and statistical tests.

###Exhibit A
#####Data Modification for Phase 1
``` {r raw.data}
Gender <- c("Cisgender Female", "Cisgender Male", "Non-Binary", 
            "I prefer not to answer", "Transgender Male", "Transgender Female",
            "These options don't define me")
vals.Z <- c(652, 401, 63, 10, 13, 5, 21)
# The data from Middlebury only has binary options for "Women" and "Men"
vals.M <- c(1416, 1240, 0, 0, 0, 0, 0)
Gender.Data.Raw <- data.frame(Gender = Gender,
                          Zeitgeist = vals.Z,
                          Middlebury = vals.M)

FinAid <- c("Yes", "No")
vals.Z <- c(485, 639)
# Middlebury data is from Fall 2021, not Spring 2022.
vals.M <- c(1315, 1520)

# Extra row ommitted, 4 "prefer not to answer"
Class.Z <- c(2022, 2022.5, 2023, 2023.5, 2024, 2024.5, 2025, 2025.5, 0)
vals.Z <- c(180, 80, 190, 79, 242, 73, 236, 50, 4)
Class.M <- c(2022,2023,2024,2025)
# Rounded data based on proportions from fall 2021
vals.M <- c(600,690,727,638)
Class.Data.Z <- data.frame(Class = Class.Z,
                         Zeitgeist = vals.Z)

# We assume that the administration combined feb and reg classes
vals.Z2 <- c(180+80, 190+79, 242+73, 236+50)

Class.Data.Raw <- data.frame(Class = Class.M,
                             Zeitgeist = vals.Z2,
                             Middlebury = vals.M)

# This data is tricky, because students had the option to check
# all boxes that applied
Race <- c("White", "Asian", "Hispanic or Latino Origin", 
          "Black or African American", "Middle Eastern or North African", 
          "I prefer not to answer", "American Indian or Alaskan Native",
          "Native Hawaiian or other Pacific Islander", "International", 
          "Two or more races", "Race and/or ethnicity unknown")
vals.Z <- c(911, 173, 96, 57, 17, 13, 8, 5, 0, 0, 0)
# "Middle Eastern or North African" and "I prefer not to answer" are not 
# categories in Middlebury's data
# "International", "Two or more races", and "Race and/or ethnicity unknown" 
# are additional categories in Middlebury data

vals.M <- c(1556, 199, 287, 125, 0, 0, 3, 0, 308, 157, 19)
Race.Data.Raw <- data.frame(Race = Race,
                        Zeitgeist = vals.Z,
                        Middlebury = vals.M)

Geography <- c("New England", "Mideast", "Southeast", "Great Lakes", "Plains", 
               "Southwest", "Rocky Mountain", "Far West", 
               "Inernational/Outside the U.S.", "I prefer not to answer")
vals.Z <- c(340, 272, 101, 63, 43, 33, 39, 136, 103, 4)
vals.M <- c(698, 604, 203, 164, 70, 78, 77, 301, 0, 143)
Geography.Data.Raw <- data.frame(Geographic.Location = Geography,
                             Zeitgeist = vals.Z,
                             Middlebury = vals.M)




Majors.Z <- c("Undeclared", "Environmental Studies", "Economics", "Political Science", "Neuroscience", "Computer Science", "English & American Literatures", "Psychology", "International & Global Studies", "Molecular Biology & Biochemistry", "Biology", "Mathematics", "International Politics & Economics", "History", "History of Art & Architecture", "Film & Media Culture", "Geography", "Anthropology", "Physics", "Spanish", "Chemistry", "Sociology", "Theatre", "Education Studies", "Music", "Philosophy", "Chinese", "Geology", "Biochemistry", "Independent Scholar", "Studio Art", "I prefer not to answer", "Arabic", "Gender, Sexuality, & Feminist Studies", "German", "Classics", "Japanese Studies", "Dance", "Russian", "French", "Religion", "American Studies", "Comparative Literature", "Literary Studies", "Black Studies", "History-Science, Medicine, and Technology", "Italian")

vals.Z <- c(162, 125, 113, 70, 68, 88, 60, 58, 50, 38, 35, 48, 44, 35, 33, 30, 25, 24, 25, 23, 22, 24, 17, 17, 15, 14, 13, 11, 10, 10, 7, 12, 12, 12, 12, 6, 5, 5, 5, 4, 4, 3, 3, 3, 2, 0, 0)
Major.Data.Z <- data.frame(Major = Majors.Z,
                         Zeitgeist = vals.Z)
    
                         
Majors.M <- c("Dance","Film & Media Culture","Music",
              "Studio Art","Theatre","Classics","History",
              "History-Science, Medicine, and Technology",
              "Philosophy","Religion", "American Studies","Black Studies",
              "Environmental Studies","Gender, Sexuality, & Feminist Studies",
              "Independent Scholar",
              "International Politics & Economics",
              "International & Global Studies","Neuroscience","Arabic",
              "Chinese",
              "French","German","Italian",
              "Japanese Studies","Russian","Spanish","Comparative Literature",
              "English & American Literatures",
              "Literary Studies","Biochemistry","Biology",  
              "Chemistry","Computer Science","Geology","Mathematics",
              "Molecular Biology & Biochemistry","Physics","Economics",
              "Education Studies","Geography",
              "Political Science","Psychology","Anthropology","Sociology",
              "Undeclared", "I prefer not to answer", 
              "History of Art & Architecture")

vals.M <- c(5,43,19,15,21,9,55,0,24,11,8,3,166,13,6,80,75,152,9,
                20,7,8,3,14,7,21,5,93,7,20,86,29,158,29,68,80,46,298,13,34,
                99,118,41,30,923,0,61)
                
Major.Data.M <- data.frame(Major = Majors.M,
                           Middlebury = vals.M)

Major.Data.Raw <- merge(Major.Data.M, Major.Data.Z, all = TRUE)
```  


###Exhibit B
#####Permutation Test for Class Category
```{r}
# Set seed so we get the same result every time
set.seed(31)

# Number of times that we will simulate samples for our sampling distribution 
N <- 100000

# The population of graduation years provided by the administration
Population <- c(rep("2022", 600), rep("2023", 690),
                rep("2024", 727), rep("2025",638))

pop.size <- length(Population)

# Expected proportions
eprop22 <- 600/pop.size
eprop23 <- 690/pop.size
eprop24 <- 727/pop.size
eprop25 <- 638/pop.size

samp.size <- sum(Class.Data.Raw$Zeitgeist)

# Expected values for sample of our size
epop22 <- eprop22*samp.size
epop23 <- eprop23*samp.size
epop24 <- eprop24*samp.size
epop25 <- eprop25*samp.size

expected.values <- c(epop22, epop23, epop24, epop25)

# test statistic is MAE
actual.test.stat <- (1/4)*sum(abs(Class.Data.Raw$Zeitgeist - expected.values))

test.stat <- NULL

# Simulating our sampling distribution
for(i in 1:N){
  # Taking a sample from our population
  samp <- sample(Population, samp.size, replace = FALSE)
  
  samp22 <- sum(samp == "2022")
  samp23 <- sum(samp == "2023")
  samp24 <- sum(samp == "2024")
  samp25 <- sum(samp == "2025")
  
  actual.samp.values <- c(samp22,samp23,samp24,samp25)
  
  # Storing the test statistic for each simulated sample
  test.stat[i] <- (1/4)*sum(abs(actual.samp.values - expected.values))
}

hist(test.stat)

# p-value: probability of finding something more extreme than actual.test.stat
mean(test.stat >= actual.test.stat)
```

###Exhibit C
#####Permutation Test for Geography Category
```{r}
# The population of regions as given by the administration data
Population <- c(rep("New England", 698), rep("Mideast", 604),
                rep("Southeast", 203), rep("Great Lakes",164),
                rep("Plains", 70), rep("Southwest", 78),
                rep("Rocky Mountain",77), rep("Far West", 301))

pop.size <- length(Population)

# Expected proportions
epropNE <- 698/pop.size
epropME <- 604/pop.size
epropSE <- 101/pop.size
epropGL <- 164/pop.size
epropP <- 70/pop.size
epropSW <- 78/pop.size
epropRM <- 77/pop.size
epropFW <- 301/pop.size

samp.size <- sum(Geography.Data.Raw$Zeitgeist[1:8])

# Expected values in a sample our size
epopNE <- epropNE*samp.size
epopME <- epropME*samp.size
epopSE <- epropSE*samp.size
epopGL <- epropGL*samp.size
epopP <- epropP*samp.size
epopSW <- epropSW*samp.size
epopRM <- epropRM*samp.size
epopFW <- epropFW*samp.size

expected.values <- c(epopNE, epopME, epopSE, epopGL,
                     epopP, epopSW, epopRM, epopFW)

#Don't want last two responses ("International" & "I prefer not to answer")
actual.test.stat <- (1/8)*sum(abs(Geography.Data.Raw$Zeitgeist[1:8] - expected.values))

test.stat <- NULL

# Simulating our sampling distribution
for(i in 1:N){
  samp <- sample(Population, samp.size, replace = FALSE)
  
  sampNE <- sum(samp == "New England")
  sampME <- sum(samp == "Mideast")
  sampSE <- sum(samp == "Southeast")
  sampGL <- sum(samp == "Great Lakes")
  sampP <- sum(samp == "Plains")
  sampSW <- sum(samp == "Southwest")
  sampRM <- sum(samp == "Rocky Mountain")
  sampFW <- sum(samp == "Far West")
  
  actual.samp.values <- c(sampNE, sampME, sampSE, sampGL,
                          sampP, sampSW, sampRM, sampFW)
  
  # Computing the test stat for our sample
  test.stat[i] <- (1/8)*sum(abs(actual.samp.values - expected.values))
}

hist(test.stat)

# p-value: the probability of observing something rarer than actual.test.stat
mean(test.stat >= actual.test.stat)
```
